{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 1 - Ciência dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nome: Maria Carolina Porto \n",
    "\n",
    "Nome: Thomas Kassabian\n",
    "\n",
    "Nome: Kaique Tinto\n",
    "\n",
    "Nome: Eduardo Candeias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "Carregando algumas bibliotecas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esperamos trabalhar no diretório\n",
      "c:\\Users\\othom\\OneDrive - Insper - Institudo de Ensino e Pesquisa\\insper\\Disciplinas\\2\\CDados\\Projetos\\CDADOS_Projeto1\n"
     ]
    }
   ],
   "source": [
    "print('Esperamos trabalhar no diretório')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregando a base de dados com as mensagens dos seus arquivos:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Classificador automático\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esse classificador tem por objetivo ensinar um Boot a classificar corretamente os reviews de clientes de uma companhia aérea. Para isso, utilizamos um dataFrame \"Train\" para treiná-lo, e um dataFrame distinto \"Test\" para testá-lo.\n",
    "\n",
    "As possíveis classificações são:\n",
    "* Detractor: Clientes que expressaram insatisfação ou descontentamento significativo com a companhia aérea;\n",
    "* Promoter: Clientes extremamente satisfeitos e leais à companhia aérea;\n",
    "* Passive: Clientes que não expressaram satisfação ou insatisfação com a companhia aérea."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Montando um Classificador Naive-Bayes\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento, ensine  seu classificador."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparação dos dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Limpeza e filtragem da base de dados\n",
    "\n",
    "- Padronização dos dados: removendo letras maiúsculas, pontuações e acentos.\n",
    "- Filtragem dos dados: removendo stopwords e palavras com duas letras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função auxiliar que limpa um texto\n",
    "\n",
    "def cleanup(text):    \n",
    "    # Retira a pontuação\n",
    "    punctuation = '[´\"!-.:?;$''()]'\n",
    "    pattern = re.compile(punctuation)\n",
    "    \n",
    "    # Retira as stopwords (palavras indiferentes para o cálculo da probabilidade)\n",
    "    stopwords = ['the','to', 'and', 'was', 'i', 'a', 'in', 'on', 'of', 'with','for', 'flight', 'we']\n",
    "    words = r'\\b(?:' + '|'.join(map(re.escape, stopwords)) + r')\\b'\n",
    "    \n",
    "    # Retira palavras de duas letras\n",
    "    limpa_duas_letras = r'\\b\\w{1,2}\\b'\n",
    "    \n",
    "\n",
    "    # Aplica as alterações e retorna o texto limpo\n",
    "    text = re.sub(pattern, '', text)\n",
    "    text = re.sub(words, '', text, flags=re.IGNORECASE)\n",
    "    text = re.sub(limpa_duas_letras, '', text)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gerando a base de dados | Contagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função auxiliar que recebe um dataframe, limpa e transforma em lista\n",
    "def transf_lista(dataframe):\n",
    "    texto = \" \"\n",
    "\n",
    "    for linha in dataframe['Review']:\n",
    "        texto += cleanup(linha)\n",
    "    \n",
    "    lista = texto.lower().split()\n",
    "    return lista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Função que recebe um dataframe e retorna as series de cada NPS e suas respectivas frequências\n",
    "\n",
    "def contagem(df):\n",
    "    # Gerando series\n",
    "    serie_df = pd.Series(transf_lista(df))\n",
    "    serie_Detractor = pd.Series(transf_lista(df.loc[(df.NPS == 'Detractor'), :]))\n",
    "    serie_Promoter = pd.Series(transf_lista(df.loc[(df.NPS == 'Promoter'), :]))\n",
    "    serie_Passive = pd.Series(transf_lista(df.loc[(df.NPS == 'Passive'), :]))\n",
    "\n",
    "    # Frequências (absolutas e relativas)\n",
    "    tabela_df = serie_df.value_counts()\n",
    "    tabela_Detractor = serie_Detractor.value_counts()\n",
    "    tabela_Promoter = serie_Promoter.value_counts()\n",
    "    tabela_Passive = serie_Passive.value_counts()\n",
    "    tabela_Detractor_relativo = serie_Detractor.value_counts(True)\n",
    "    tabela_Promoter_relativo = serie_Promoter.value_counts(True)\n",
    "    tabela_Passive_relativo = serie_Passive.value_counts(True)\n",
    "\n",
    "    # Return all variables\n",
    "    return locals()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função auxiliar que calcula a probabilidade de uma palavra estar em um NPS (classificação) específico\n",
    "\n",
    "# Recebe: palavra -> palavra que se deseja calcular a probabilidade;\n",
    "#         tab_NPS -> tabela de um NPS específico;\n",
    "#         len_serie_NPS -> quantidade de palavras totais (com repetição) em um NPS específico.\n",
    "\n",
    "def calc_prob(palavra, tab_NPS, len_serie_NPS, tabela_train):\n",
    "    prob = 1\n",
    "    # Se a palavra estiver na tabela do NPS específico\n",
    "    if palavra in tab_NPS:\n",
    "        prob = ((tab_NPS[palavra] + 1)/(len_serie_NPS + len(tabela_train)))*1e3\n",
    "        \n",
    "    # Se a palavra for inédita\n",
    "    else:   \n",
    "        prob = (1/(len_serie_NPS + len(tabela_train)))*1e3\n",
    "\n",
    "    return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Classifica a frase em detractor, promoter, passive\n",
    "\n",
    "def classificador(tabela_Detractor, tabela_Passive, tabela_Promoter, tabela_df, serie_Detractor, serie_Passive, serie_Promoter, serie_df, df):\n",
    "    classif = []\n",
    "\n",
    "    # Probabilidades de cada NPS específico\n",
    "    P_D = len(serie_Detractor)/len(serie_df)\n",
    "    P_Pa = len(serie_Passive)/len(serie_df)\n",
    "    P_Pr = len(serie_Promoter)/len(serie_df)\n",
    "\n",
    "    P_NPS = [P_D, P_Pa, P_Pr]\n",
    "\n",
    "    # Loop que percorre todos os reviews do dataFrame\n",
    "    for frase in df.Review:\n",
    "\n",
    "        #Limpar a frase\n",
    "        frase_limpa = cleanup(frase)\n",
    "        frase_limpa = frase_limpa.lower().split()\n",
    "        \n",
    "        P_frase_dado_D = 1\n",
    "        P_frase_dado_Pa = 1 \n",
    "        P_frase_dado_Pr = 1\n",
    "\n",
    "        # For que percorre cada palavra das frases\n",
    "        for palavra in frase_limpa:\n",
    "\n",
    "            #Probabilidade da frase ser de cada NPS específico\n",
    "            P_frase_dado_D *= calc_prob(palavra, tabela_Detractor, len(serie_Detractor), tabela_df)\n",
    "            P_frase_dado_Pa *= calc_prob(palavra, tabela_Passive, len(serie_Passive), tabela_df)\n",
    "            P_frase_dado_Pr *= calc_prob(palavra, tabela_Promoter, len(serie_Promoter), tabela_df)\n",
    "\n",
    "        #Probabilidade de cada NPS específico para a frase\n",
    "        P_D_dado_frase = (P_frase_dado_D * P_D)\n",
    "        P_Pa_dado_frase = (P_frase_dado_Pa * P_Pa)\n",
    "        P_Pr_dado_frase = (P_frase_dado_Pr * P_Pr)\n",
    "\n",
    "        # Armazena as probabilidades, compara e adiciona a maior classif na lista \n",
    "        prob = [P_D_dado_frase, P_Pa_dado_frase, P_Pr_dado_frase]\n",
    "\n",
    "        if max(prob) == prob[0]:\n",
    "            classif.append(\"Detractor\")\n",
    "        elif max(prob) == prob[1]:\n",
    "            classif.append(\"Passive\")\n",
    "        elif max(prob) == prob[2]:\n",
    "            classif.append(\"Promoter\")\n",
    "        \n",
    "    return classif, P_NPS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "### Treinamento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classificação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe\n",
    "train = pd.read_csv('dados_treino_QUARTETO_Thomas.csv')\n",
    "\n",
    "# Contagem\n",
    "dados_treino = contagem(train)\n",
    "\n",
    "tabela_Detractor_treino = dados_treino['tabela_Detractor']\n",
    "tabela_Passive_treino = dados_treino['tabela_Passive']\n",
    "tabela_Promoter_treino = dados_treino['tabela_Promoter']\n",
    "tabela_train = dados_treino['tabela_df']\n",
    "serie_train = dados_treino['serie_df']\n",
    "serie_Detractor_treino = dados_treino['serie_Detractor']\n",
    "serie_Promoter_treino = dados_treino['serie_Promoter']\n",
    "serie_Passive_treino = dados_treino['serie_Passive']\n",
    "\n",
    "# Classificação\n",
    "classificacao = classificador(tabela_Detractor_treino, tabela_Passive_treino, tabela_Promoter_treino, tabela_train, serie_Detractor_treino, serie_Passive_treino, serie_Promoter_treino, serie_train, train)\n",
    "\n",
    "# Probabilidade de cada NPS (será utilizado no teste)\n",
    "P_NPS = classificacao[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verificação dos resultados\n",
    "Comparação do NPS com as classificações fornecidas pelo classificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia: 85.67%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>NPS</th>\n",
       "      <th>Boot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bangkok to Phuket round trip. The lounge at th...</td>\n",
       "      <td>Promoter</td>\n",
       "      <td>Promoter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A real mixed bag with Air New Zealand from Auc...</td>\n",
       "      <td>Passive</td>\n",
       "      <td>Passive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Second in the queue in business class check-...</td>\n",
       "      <td>Detractor</td>\n",
       "      <td>Detractor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>London Heathrow to Riyadh return. Pleasant f...</td>\n",
       "      <td>Promoter</td>\n",
       "      <td>Promoter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hong Kong to Bangkok. Check-in at the transf...</td>\n",
       "      <td>Promoter</td>\n",
       "      <td>Promoter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4193</th>\n",
       "      <td>Great Christmas holiday in Spain starting wit...</td>\n",
       "      <td>Promoter</td>\n",
       "      <td>Promoter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4194</th>\n",
       "      <td>Gothenburg to London. Flights were on time. S...</td>\n",
       "      <td>Detractor</td>\n",
       "      <td>Detractor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4196</th>\n",
       "      <td>After 3 hours in the plane waiting for repairs...</td>\n",
       "      <td>Detractor</td>\n",
       "      <td>Detractor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4198</th>\n",
       "      <td>My mother left on AI 43 MAA-DEL connecting AI ...</td>\n",
       "      <td>Promoter</td>\n",
       "      <td>Promoter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4199</th>\n",
       "      <td>We had the most amazing flight crew on the wa...</td>\n",
       "      <td>Promoter</td>\n",
       "      <td>Promoter</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3598 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Review        NPS       Boot\n",
       "0     Bangkok to Phuket round trip. The lounge at th...   Promoter   Promoter\n",
       "1     A real mixed bag with Air New Zealand from Auc...    Passive    Passive\n",
       "2       Second in the queue in business class check-...  Detractor  Detractor\n",
       "3       London Heathrow to Riyadh return. Pleasant f...   Promoter   Promoter\n",
       "4       Hong Kong to Bangkok. Check-in at the transf...   Promoter   Promoter\n",
       "...                                                 ...        ...        ...\n",
       "4193   Great Christmas holiday in Spain starting wit...   Promoter   Promoter\n",
       "4194   Gothenburg to London. Flights were on time. S...  Detractor  Detractor\n",
       "4196  After 3 hours in the plane waiting for repairs...  Detractor  Detractor\n",
       "4198  My mother left on AI 43 MAA-DEL connecting AI ...   Promoter   Promoter\n",
       "4199   We had the most amazing flight crew on the wa...   Promoter   Promoter\n",
       "\n",
       "[3598 rows x 3 columns]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Incrementando o dataframe com a classificação fornecida pelo classificador\n",
    "train['Boot'] = classificacao[0]\n",
    "\n",
    "# Assertividade\n",
    "acuracia_train = len(train.loc[(train.NPS == train.Boot), :])/len(train)\n",
    "print(f'Acurácia: {acuracia_train*100:.2f}%')\n",
    "\n",
    "# DF com os reviews classificados corretamente\n",
    "train.loc[(train.NPS == train.Boot), :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crosstab (NPS x Boot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Boot</th>\n",
       "      <th>Detractor</th>\n",
       "      <th>Passive</th>\n",
       "      <th>Promoter</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NPS</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Detractor</th>\n",
       "      <td>1751</td>\n",
       "      <td>110</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Passive</th>\n",
       "      <td>109</td>\n",
       "      <td>412</td>\n",
       "      <td>165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Promoter</th>\n",
       "      <td>113</td>\n",
       "      <td>1</td>\n",
       "      <td>1435</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Boot       Detractor  Passive  Promoter\n",
       "NPS                                    \n",
       "Detractor       1751      110       104\n",
       "Passive          109      412       165\n",
       "Promoter         113        1      1435"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(train.NPS, train.Boot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Testes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classificação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe\n",
    "test = pd.read_csv('dados_teste_QUARTETO_Thomas.csv')\n",
    "\n",
    "# Contagem\n",
    "dados_teste = contagem(test)\n",
    "\n",
    "tabela_Detractor_teste = dados_teste['tabela_Detractor']\n",
    "tabela_Passive_teste = dados_teste['tabela_Passive']\n",
    "tabela_Promoter_teste = dados_teste['tabela_Promoter']\n",
    "tabela_teste = dados_teste['tabela_df']\n",
    "serie_teste = dados_teste['serie_df']\n",
    "serie_Detractor_teste = dados_teste['serie_Detractor']\n",
    "serie_Promoter_teste = dados_teste['serie_Promoter']\n",
    "serie_Passive_teste = dados_teste['serie_Passive']\n",
    "    \n",
    "# Classificação\n",
    "classificacao_teste = classificador(tabela_Detractor_teste, tabela_Passive_teste, tabela_Promoter_teste, tabela_teste, serie_Detractor_teste, serie_Passive_teste, serie_Promoter_teste, serie_teste, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verificação os resultados\n",
    "Comparação do NPS com as classificações fornecidas pelo classificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia: 88.28%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>NPS</th>\n",
       "      <th>Boot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Melbourne to Singapore on a Singapore Airlines...</td>\n",
       "      <td>Promoter</td>\n",
       "      <td>Promoter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Palermo to Moscow via Rome and I was so unluc...</td>\n",
       "      <td>Detractor</td>\n",
       "      <td>Detractor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Flew Spirit Airlines from Orlando to Boston....</td>\n",
       "      <td>Detractor</td>\n",
       "      <td>Detractor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Shockingly poor experience on many levels, as...</td>\n",
       "      <td>Detractor</td>\n",
       "      <td>Detractor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Athens to Cairo. There is nothing special abo...</td>\n",
       "      <td>Promoter</td>\n",
       "      <td>Promoter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1794</th>\n",
       "      <td>I flew round trip with Cathay from New York t...</td>\n",
       "      <td>Detractor</td>\n",
       "      <td>Detractor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1795</th>\n",
       "      <td>I broke my foot on my vacation and the entire ...</td>\n",
       "      <td>Promoter</td>\n",
       "      <td>Promoter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1796</th>\n",
       "      <td>LHR-PEK-Tokyo RT in Business. One-word comment...</td>\n",
       "      <td>Passive</td>\n",
       "      <td>Passive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1797</th>\n",
       "      <td>Gatwick to Fort Lauderdale. Charging to choos...</td>\n",
       "      <td>Detractor</td>\n",
       "      <td>Detractor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1799</th>\n",
       "      <td>TLL-RIX-KPB economy. High overall price despit...</td>\n",
       "      <td>Promoter</td>\n",
       "      <td>Promoter</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1589 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Review        NPS       Boot\n",
       "0     Melbourne to Singapore on a Singapore Airlines...   Promoter   Promoter\n",
       "1      Palermo to Moscow via Rome and I was so unluc...  Detractor  Detractor\n",
       "3       Flew Spirit Airlines from Orlando to Boston....  Detractor  Detractor\n",
       "4      Shockingly poor experience on many levels, as...  Detractor  Detractor\n",
       "5      Athens to Cairo. There is nothing special abo...   Promoter   Promoter\n",
       "...                                                 ...        ...        ...\n",
       "1794   I flew round trip with Cathay from New York t...  Detractor  Detractor\n",
       "1795  I broke my foot on my vacation and the entire ...   Promoter   Promoter\n",
       "1796  LHR-PEK-Tokyo RT in Business. One-word comment...    Passive    Passive\n",
       "1797   Gatwick to Fort Lauderdale. Charging to choos...  Detractor  Detractor\n",
       "1799  TLL-RIX-KPB economy. High overall price despit...   Promoter   Promoter\n",
       "\n",
       "[1589 rows x 3 columns]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['Boot'] = classificacao_teste[0]\n",
    "\n",
    "# Assertividade\n",
    "acuracia_teste = len(test.loc[(test.NPS == test.Boot), :])/len(test)\n",
    "print(f'Acurácia: {acuracia_teste*100:.2f}%')\n",
    "\n",
    "# DF com os reviews classificados corretamente\n",
    "test.loc[(test.NPS == test.Boot), :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crosstab (NPS x Boot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Boot</th>\n",
       "      <th>Detractor</th>\n",
       "      <th>Passive</th>\n",
       "      <th>Promoter</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NPS</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Detractor</th>\n",
       "      <td>719</td>\n",
       "      <td>86</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Passive</th>\n",
       "      <td>86</td>\n",
       "      <td>39</td>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Promoter</th>\n",
       "      <td>83</td>\n",
       "      <td>23</td>\n",
       "      <td>574</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Boot       Detractor  Passive  Promoter\n",
       "NPS                                    \n",
       "Detractor        719       86        45\n",
       "Passive           86       39       145\n",
       "Promoter          83       23       574"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(test.NPS, test.Boot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Porcentagens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia: 88.28%\n",
      "\n",
      "Promoter\n",
      " Verdadeiros: 93.53%\n",
      " Falsos: 6.47%\n",
      "\n",
      "Passive\n",
      " Verdadeiros: 57.41%\n",
      " Falsos: 42.59%\n",
      "\n",
      "Detractor\n",
      " Verdadeiros: 93.88%\n",
      " Falsos: 6.12%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "total_promoter = len(test.loc[test.NPS == 'Promoter', :])\n",
    "total_passive = len(test.loc[test.NPS == 'Passive', :])\n",
    "total_detractor = len(test.loc[test.NPS == 'Detractor', :])\n",
    "\n",
    "# Classificados corretamente\n",
    "certo_promoter = len(test.loc[(test.NPS == 'Promoter') & (test.Boot == 'Promoter'), :])\n",
    "certo_passive = len(test.loc[(test.NPS == 'Passive') & (test.Boot == 'Passive'), :])\n",
    "certo_detractor = len(test.loc[(test.NPS == 'Detractor') & (test.Boot == 'Detractor'), :])\n",
    "\n",
    "# Classificados incorretamente\n",
    "errado_promoter = 1 - certo_promoter/total_promoter\n",
    "errado_passive = 1 - certo_passive/total_passive\n",
    "errado_detractor = 1 - certo_detractor/total_detractor\n",
    "\n",
    "# Acurácia\n",
    "acuracia_test = len(test.loc[(test.NPS == test.Boot), :])/len(test)\n",
    "\n",
    "# Print\n",
    "print('Acurácia: {:.2f}%\\n'.format(acuracia_test*100))\n",
    "print(f'Promoter\\n Verdadeiros: {certo_promoter/total_promoter*100:.2f}%\\n Falsos: {errado_promoter*100:.2f}%\\n')\n",
    "print(f'Passive\\n Verdadeiros: {certo_passive/total_passive*100:.2f}%\\n Falsos: {errado_passive*100:.2f}%\\n')\n",
    "print(f'Detractor\\n Verdadeiros: {certo_detractor/total_detractor*100:.2f}%\\n Falsos: {errado_detractor*100:.2f}%\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Concluindo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Qualidade do Classificador a partir de novas separações das mensagens entre Treinamento e Teste\n",
    "\n",
    "Caso for fazer esse item do Projeto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados = pd.concat([train, test])\n",
    "dados = dados.drop(columns=['Boot'])\n",
    "\n",
    "for i in range(100,101):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(dados.Review, dados.NPS, test_size=0.3, random_state=i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Aperfeiçoamento:\n",
    "\n",
    "Trabalhos que conseguirem pelo menos conceito B vão evoluir em conceito dependendo da quantidade de itens avançados:\n",
    "\n",
    "* OK IMPLEMENTOU outras limpezas e transformações que não afetem a qualidade da informação contida nas mensagens. Ex: stemming, lemmatization, stopwords\n",
    "* OK CONSIDEROU arquivo com três categorias na classificação das variáveis (OBRIGATÓRIO PARA QUARTETOS, sem contar como item avançado)\n",
    "* OK CONSTRUIU o cálculo das probabilidades corretamente utilizando bigramas E apresentou referência sobre o método utilizado.\n",
    "* EXPLICOU porquê não pode usar o próprio classificador para gerar mais amostras de treinamento\n",
    "* OK PROPÔS diferentes cenários para Naïve Bayes fora do contexto do projeto (pelo menos dois cenários diferentes, exceto aqueles já apresentados em sala pelos professores: por exemplo, filtro de spam)\n",
    "* OK SUGERIU e EXPLICOU melhorias reais com indicações concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n",
    "* FEZ o item Qualidade do Classificador a partir de novas separações das mensagens entre Treinamento e Teste descrito no enunciado do projeto (OBRIGATÓRIO para conceitos A ou A+)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Itens avançados:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Porque não pode usar o próprio classificador para gerar mais amostras de treinamento?\n",
    "* Não podemos usar o proprio classificador para gerar mais amostras de treinamento, pois o classificador já foi treinado com esses dados.\n",
    "2) Diferentes cenários para Naïve Bayes fora do contexto do projeto:\n",
    "* Detectar Fake News;\n",
    "* Detectar mensagens ofensivas/ inapropriadas para, possivelmente, retirar da internet;\n",
    "3) Possíveis melhorias para o projeto:\n",
    "* Aplicar os métodos stemming e lemmatization na limpeza das frases.\n",
    "Stemming: Analisa cada palavra individualmente e a reduz para o seu radical (não será necessariamente gramaticamente correta);\n",
    "Lemmatization: Analisa cada palavra individualmente e a reduz para o seu radical (será necessariamente gramaticamente correta);\n",
    "Ambos os métodos podem melhorar a nossa ánalise ao juntar palavras difernetes mas com o radical semelhante, alterando a probabilidade final e, portanto, a classificação final.\n",
    "Material de pesquisa em \"Referências\"\n",
    "\n",
    "* Aplicar metodos de redes neurais, para podermos considerar a semantica e ordem das palavras, com o intuito de aumentar a assertividade do código.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Referências"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**\n",
    "\n",
    "[Lemmatization vs. stemming: quando usar cada uma?](https://www.alura.com.br/artigos/lemmatization-vs-stemming-quando-usar-cada-uma) **Diferenças entre Lemmatization e stemming, e como aplicar cada uma**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# O modelo probabilistico para o calculo e classificação de texto, se baseia na probabilidade de uma palavra estar em um NPS específico. Fizemos o uso do metodo de Naive Bayes para calcular a probabilidade de uma palavra estar em um NPS específico. Com o intuito de minimizar os erros e maximizar a porcentagem de acertividade, aplicamos a suavização de Laplace dentro do código "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
