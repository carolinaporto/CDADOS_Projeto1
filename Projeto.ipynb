{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 1 - Ciência dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nome: Maria Carolina Porto \n",
    "\n",
    "Nome: Thomas Kassabian\n",
    "\n",
    "Nome: Kaique Tinto\n",
    "\n",
    "Nome: Eduardo Candeias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "Carregando algumas bibliotecas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esperamos trabalhar no diretório\n",
      "c:\\Users\\othom\\OneDrive - Insper - Institudo de Ensino e Pesquisa\\insper\\Disciplinas\\2\\CDados\\Projetos\\CDADOS_Projeto1\n"
     ]
    }
   ],
   "source": [
    "print('Esperamos trabalhar no diretório')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregando a base de dados com as mensagens dos seus arquivos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('dados_treino_QUARTETO_Thomas.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('dados_teste_QUARTETO_Thomas.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Classificador automático\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esse classificador tem por objetivo ensinar um Boot a classificar corretamente os reviews de clientes de uma companhia aérea. Para isso, utilizamos um dataFrame \"Train\" para treiná-lo, e um dataFrame distinto \"Test\" para testá-lo.\n",
    "\n",
    "As possíveis classificações são:\n",
    "* Detractor: Clientes que expressaram insatisfação ou descontentamento significativo com a companhia aérea;\n",
    "* Promoter: Clientes extremamente satisfeitos e leais à companhia aérea;\n",
    "* Passive: Clientes que não expressaram satisfação ou insatisfação com a companhia aérea."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Montando um Classificador Naive-Bayes\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento, ensine  seu classificador."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparação dos dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Limpeza e filtragem da base de dados\n",
    "\n",
    "- Padronização dos dados: removendo letras maiúsculas, pontuações e acentos.\n",
    "- Filtragem dos dados: removendo stopwords e palavras com duas letras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função que limpa um texto\n",
    "\n",
    "import re\n",
    "\n",
    "def cleanup(text):    \n",
    "    # Retira a pontuação\n",
    "    punctuation = '[´\"!-.:?;$''()]'\n",
    "    pattern = re.compile(punctuation)\n",
    "    \n",
    "    # Retira as stopwords (palavras indiferentes para o cálculo da probabilidade)\n",
    "    stopwords = ['the','to', 'and', 'was', 'i', 'a', 'in', 'on', 'of', 'with','for', 'flight', 'we']\n",
    "    words = r'\\b(?:' + '|'.join(map(re.escape, stopwords)) + r')\\b'\n",
    "    \n",
    "    # Retira palavras de duas letras\n",
    "    limpa_duas_letras = r'\\b\\w{1,2}\\b'\n",
    "    \n",
    "\n",
    "    # Aplica as alterações e retorna o texto limpo\n",
    "    text = re.sub(pattern, '', text)\n",
    "    text = re.sub(words, '', text, flags=re.IGNORECASE)\n",
    "    text = re.sub(limpa_duas_letras, '', text)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gerando a base de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função que recebe um dataframe, limpa e transforma em lista\n",
    "def transf_lista(dataframe):\n",
    "    texto = \" \"\n",
    "\n",
    "    for linha in dataframe['Review']:\n",
    "        texto += cleanup(linha)\n",
    "    \n",
    "    lista = texto.lower().split()\n",
    "    return lista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Criando pd.Series para cada classificação distinta e para o total\n",
    "# pdSeires com repetição de palavras\n",
    "\n",
    "serie_train = pd.Series(transf_lista(train))\n",
    "serie_Detractor = pd.Series(transf_lista(train.loc[(train.NPS == 'Detractor'), :]))\n",
    "serie_Promoter = pd.Series(transf_lista(train.loc[(train.NPS == 'Promoter'), :]))\n",
    "serie_Passive = pd.Series(transf_lista(train.loc[(train.NPS == 'Passive'), :]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Contagem dos dados (frequência absoluta e relativa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando uma tabela com a contagem de cada palavra em cada classificação\n",
    "# pdSeries sem repetição de palavras\n",
    "\n",
    "tabela_train = serie_train.value_counts()\n",
    "tabela_Detractor = serie_Detractor.value_counts()\n",
    "tabela_Promoter = serie_Promoter.value_counts()\n",
    "tabela_Passive = serie_Passive.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Criando uma tabela com a porcentagem relativa de cada palavra em cada classificação\n",
    "\n",
    "tabela_Detractor_relativo = serie_Detractor.value_counts(True)\n",
    "tabela_Promoter_relativo = serie_Promoter.value_counts(True)\n",
    "tabela_Passive_relativo = serie_Passive.value_counts(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função que calcula a probabilidade de uma palavra estar em um NPS (classificação) específico\n",
    "\n",
    "# Recebe: palavra -> palavra que se deseja calcular a probabilidade;\n",
    "#         tab_NPS -> tabela de um NPS específico;\n",
    "#         len_serie_NPS -> quantidade de palavras totais (com repetição) em um NPS específico.\n",
    "\n",
    "def calc_prob(palavra, tab_NPS, len_serie_NPS):\n",
    "    prob = 1\n",
    "    # Se a palavra estiver na tabela do NPS específico\n",
    "    if palavra in tab_NPS:\n",
    "        prob = ((tab_NPS[palavra] + 1)/(len_serie_NPS+ len(tabela_train)))*1e3\n",
    "        \n",
    "    # Se a palavra for inédita\n",
    "    else:   \n",
    "        prob = (1/(len_serie_NPS + len(tabela_train)))*1e3\n",
    "\n",
    "    return prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "### Treinamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cálculo das probabilidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probabilidade da palavra ser de cada NPS específico em relação ao total\n",
    "\n",
    "P_D = len(serie_Detractor)/len(serie_train)\n",
    "P_Pa = len(serie_Passive)/len(serie_train)\n",
    "P_Pr = len(serie_Promoter)/len(serie_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Classifica a frase em detractor, promoter, passive\n",
    "\n",
    "classif = []\n",
    "\n",
    "# For que percorre todos os reviews do dataFrame\n",
    "for frase in train.Review:\n",
    "\n",
    "    #Limpar a frase\n",
    "    frase_limpa = cleanup(frase)\n",
    "    frase_limpa = frase_limpa.lower().split()\n",
    "    \n",
    "    P_frase_dado_D = 1\n",
    "    P_frase_dado_Pa = 1 \n",
    "    P_frase_dado_Pr = 1\n",
    "\n",
    "    # For que percorre cada palavra das frases\n",
    "    for palavra in frase_limpa:\n",
    "\n",
    "        #Probabilidade da frase ser de cada NPS específico\n",
    "        P_frase_dado_D *= calc_prob(palavra, tabela_Detractor, len(serie_Detractor))\n",
    "        P_frase_dado_Pa *= calc_prob(palavra, tabela_Passive, len(serie_Passive))\n",
    "        P_frase_dado_Pr *= calc_prob(palavra, tabela_Promoter, len(serie_Promoter))\n",
    "\n",
    "    #Probabilidade de cada NPS específico para a frase\n",
    "    P_D_dado_frase = (P_frase_dado_D * P_D)\n",
    "    P_Pa_dado_frase = (P_frase_dado_Pa * P_Pa)\n",
    "    P_Pr_dado_frase = (P_frase_dado_Pr * P_Pr)\n",
    "\n",
    "    # Armazena as probabilidades, compara e adiciona a maior classif na lista \n",
    "    prob = [P_D_dado_frase, P_Pa_dado_frase, P_Pr_dado_frase]\n",
    "\n",
    "    if max(prob) == prob[0]:\n",
    "        classif.append(\"Detractor\")\n",
    "    elif max(prob) == prob[1]:\n",
    "        classif.append(\"Passive\")\n",
    "    elif max(prob) == prob[2]:\n",
    "        classif.append(\"Promoter\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verificando os resultados\n",
    "\n",
    "Comparação do NPS com a classificação fornecida pelo programa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Asssertividade: 85.67%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>NPS</th>\n",
       "      <th>Boot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bangkok to Phuket round trip. The lounge at th...</td>\n",
       "      <td>Promoter</td>\n",
       "      <td>Promoter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A real mixed bag with Air New Zealand from Auc...</td>\n",
       "      <td>Passive</td>\n",
       "      <td>Passive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Second in the queue in business class check-...</td>\n",
       "      <td>Detractor</td>\n",
       "      <td>Detractor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>London Heathrow to Riyadh return. Pleasant f...</td>\n",
       "      <td>Promoter</td>\n",
       "      <td>Promoter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hong Kong to Bangkok. Check-in at the transf...</td>\n",
       "      <td>Promoter</td>\n",
       "      <td>Promoter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4193</th>\n",
       "      <td>Great Christmas holiday in Spain starting wit...</td>\n",
       "      <td>Promoter</td>\n",
       "      <td>Promoter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4194</th>\n",
       "      <td>Gothenburg to London. Flights were on time. S...</td>\n",
       "      <td>Detractor</td>\n",
       "      <td>Detractor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4196</th>\n",
       "      <td>After 3 hours in the plane waiting for repairs...</td>\n",
       "      <td>Detractor</td>\n",
       "      <td>Detractor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4198</th>\n",
       "      <td>My mother left on AI 43 MAA-DEL connecting AI ...</td>\n",
       "      <td>Promoter</td>\n",
       "      <td>Promoter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4199</th>\n",
       "      <td>We had the most amazing flight crew on the wa...</td>\n",
       "      <td>Promoter</td>\n",
       "      <td>Promoter</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3598 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Review        NPS       Boot\n",
       "0     Bangkok to Phuket round trip. The lounge at th...   Promoter   Promoter\n",
       "1     A real mixed bag with Air New Zealand from Auc...    Passive    Passive\n",
       "2       Second in the queue in business class check-...  Detractor  Detractor\n",
       "3       London Heathrow to Riyadh return. Pleasant f...   Promoter   Promoter\n",
       "4       Hong Kong to Bangkok. Check-in at the transf...   Promoter   Promoter\n",
       "...                                                 ...        ...        ...\n",
       "4193   Great Christmas holiday in Spain starting wit...   Promoter   Promoter\n",
       "4194   Gothenburg to London. Flights were on time. S...  Detractor  Detractor\n",
       "4196  After 3 hours in the plane waiting for repairs...  Detractor  Detractor\n",
       "4198  My mother left on AI 43 MAA-DEL connecting AI ...   Promoter   Promoter\n",
       "4199   We had the most amazing flight crew on the wa...   Promoter   Promoter\n",
       "\n",
       "[3598 rows x 3 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cria uma nova coluna com as classificações do Boot\n",
    "train['Boot'] = classif\n",
    "\n",
    "# Assertividade\n",
    "assertividade = len(train.loc[(train.NPS == train.Boot), :])/len(train)\n",
    "print('Asssertividade: {:.2f}%'.format(assertividade*100))\n",
    "\n",
    "# DF com os reviews classificados corretamente\n",
    "certo = train.loc[train.NPS == train.Boot, :]\n",
    "certo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crosstab (NPS x Boot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Boot</th>\n",
       "      <th>Detractor</th>\n",
       "      <th>Passive</th>\n",
       "      <th>Promoter</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NPS</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Detractor</th>\n",
       "      <td>1751</td>\n",
       "      <td>110</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Passive</th>\n",
       "      <td>109</td>\n",
       "      <td>412</td>\n",
       "      <td>165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Promoter</th>\n",
       "      <td>113</td>\n",
       "      <td>1</td>\n",
       "      <td>1435</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Boot       Detractor  Passive  Promoter\n",
       "NPS                                    \n",
       "Detractor       1751      110       104\n",
       "Passive          109      412       165\n",
       "Promoter         113        1      1435"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(train.NPS, train.Boot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Testes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cálculo das probabilidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "classif_test = []\n",
    "\n",
    "for frase in test.Review:\n",
    "\n",
    "    #Limpar a frase\n",
    "    frase_limpa = cleanup(frase)\n",
    "    frase_limpa = frase_limpa.lower().split()\n",
    "    \n",
    "    P_frase_dado_D = 1\n",
    "    P_frase_dado_Pa = 1 \n",
    "    P_frase_dado_Pr = 1\n",
    "\n",
    "    # For que percorre cada palavra das frases\n",
    "    for palavra in frase_limpa:\n",
    "\n",
    "        #Probabilidade da frase ser de cada NPS específico\n",
    "        P_frase_dado_D *= calc_prob(palavra, tabela_Detractor, len(serie_Detractor))\n",
    "        P_frase_dado_Pa *= calc_prob(palavra, tabela_Passive, len(serie_Passive))\n",
    "        P_frase_dado_Pr *= calc_prob(palavra, tabela_Promoter, len(serie_Promoter))\n",
    "\n",
    "    #Probabilidade de cada NPS específico para a frase\n",
    "    P_D_dado_frase = (P_frase_dado_D * P_D)\n",
    "    P_Pa_dado_frase = (P_frase_dado_Pa * P_Pa)\n",
    "    P_Pr_dado_frase = (P_frase_dado_Pr * P_Pr)\n",
    "\n",
    "    # Armazena as probabilidades, compara e adiciona a maior classif na lista \n",
    "    prob = [P_D_dado_frase, P_Pa_dado_frase, P_Pr_dado_frase]\n",
    "\n",
    "    if max(prob) == prob[0]:\n",
    "        classif_test.append(\"Detractor\")\n",
    "    elif max(prob) == prob[1]:\n",
    "        classif_test.append(\"Passive\")\n",
    "    elif max(prob) == prob[2]:\n",
    "        classif_test.append(\"Promoter\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verificando os resultados\n",
    "Comparação do NPS com a classificação fornecida pelo programa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crosstab (NPS x Boot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Boot</th>\n",
       "      <th>Detractor</th>\n",
       "      <th>Passive</th>\n",
       "      <th>Promoter</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NPS</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Detractor</th>\n",
       "      <td>719</td>\n",
       "      <td>86</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Passive</th>\n",
       "      <td>86</td>\n",
       "      <td>39</td>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Promoter</th>\n",
       "      <td>83</td>\n",
       "      <td>23</td>\n",
       "      <td>574</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Boot       Detractor  Passive  Promoter\n",
       "NPS                                    \n",
       "Detractor        719       86        45\n",
       "Passive           86       39       145\n",
       "Promoter          83       23       574"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(test.NPS, test.Boot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Porcentagens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Asssertividade: 74.00%\n",
      "\n",
      "Promoter\n",
      " Verdadeiros: 84.41%\n",
      " Falsos: 15.59%\n",
      "\n",
      "Passive\n",
      " Verdadeiros: 14.44%\n",
      " Falsos: 85.56%\n",
      "\n",
      "Detractor\n",
      " Verdadeiros: 84.59%\n",
      " Falsos: 15.41%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "total_promoter = len(test.loc[test.NPS == 'Promoter', :])\n",
    "total_passive = len(test.loc[test.NPS == 'Passive', :])\n",
    "total_detractor = len(test.loc[test.NPS == 'Detractor', :])\n",
    "\n",
    "# Classificados corretamente\n",
    "certo_promoter = len(test.loc[(test.NPS == 'Promoter') & (test.Boot == 'Promoter'), :])\n",
    "certo_passive = len(test.loc[(test.NPS == 'Passive') & (test.Boot == 'Passive'), :])\n",
    "certo_detractor = len(test.loc[(test.NPS == 'Detractor') & (test.Boot == 'Detractor'), :])\n",
    "\n",
    "# Classificados incorretamente\n",
    "errado_promoter = 1 - certo_promoter/total_promoter\n",
    "errado_passive = 1 - certo_passive/total_passive\n",
    "errado_detractor = 1 - certo_detractor/total_detractor\n",
    "\n",
    "# Acurácia\n",
    "acuracia_test = len(test.loc[(test.NPS == test.Boot), :])/len(test)\n",
    "\n",
    "# Print\n",
    "print('Asssertividade: {:.2f}%\\n'.format(acuracia_test*100))\n",
    "print(f'Promoter\\n Verdadeiros: {certo_promoter/total_promoter*100:.2f}%\\n Falsos: {errado_promoter*100:.2f}%\\n')\n",
    "print(f'Passive\\n Verdadeiros: {certo_passive/total_passive*100:.2f}%\\n Falsos: {errado_passive*100:.2f}%\\n')\n",
    "print(f'Detractor\\n Verdadeiros: {certo_detractor/total_detractor*100:.2f}%\\n Falsos: {errado_detractor*100:.2f}%\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Concluindo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Comparativo entre os percentuais:**\n",
    "\n",
    "O classificador tende a identificar corretamente reviews classificadas como \"Promoter\" e \"Detractor\". Entretanto, reviews referentes a classificação \"Passive\" possuem elevado índice de erro. \n",
    "\n",
    "\n",
    "**2. Dupla negação e sarcasmo:**\n",
    "\n",
    "Reviews com dupla negação, que nós humanos identificamos como algo positivo, o classificador identificará como duas vezes algo negativo, aumentando a probabilidade de ser classificada como \"Detractor\", quando provavelmente não é. Por ooutro lado, reviews com sarcasmo, que nós humanos identificamos como algo negativo, o classificador identificará como algo positivo, aumentando a probabilidade de ser classificada como \"Promoter\", quando provavelmente não é. \n",
    "\n",
    "Ou seja, duplas negações e frases sarcásticas aumentam as chances de classificação incorreta.\n",
    "\n",
    "**3. Plano de expansão:**\n",
    "\n",
    "O nosso projeto deve continuar sendo financiado pois a classificação das reviews dos clientes da companhia aérea auxilia positivamente a empresa, uma vez que eles conseguem identificar, por meio de dados concretos, se os clientes estão contentes ou não com os serviços oferecidos. Além disso, é possível identificar quais são os principais pontos de contentamento e descontentamento, os quais, somado a um plano de ação da empresa, possibilitará melhorias na companhia, buscando melhorar os serviços oferecidos e a experiência do usuário. \n",
    "\n",
    "Além disso, caso a companhia desejasse enviar reviews positivas e negativas para setores distintos, o classificador removeria a necessidade de que um funcionário lesse cada review e a classificasse, poupando tempo e recursos financeiros da empresa, uma vez que um classificador faria automaticamente tal divisão. \n",
    "\n",
    "**4. Diferentes cenários para Naïve Bayes fora do contexto do projeto:**\n",
    "\n",
    "* Detectar Fake News;\n",
    "\n",
    "* Detectar mensagens ofensivas/ inapropriadas para, possivelmente, retirar da internet;\n",
    "\n",
    "**5. Possíveis melhorias para o projeto:**\n",
    "\n",
    "* Aplicar os métodos stemming e lemmatization na limpeza das frases.\n",
    "\n",
    "Stemming: Analisa cada palavra individualmente e a reduz para o seu radical (não será necessariamente gramaticamente correta);\n",
    "\n",
    "Lemmatization: Analisa cada palavra individualmente e a reduz para o seu radical (será necessariamente gramaticamente correta);\n",
    "\n",
    "Ambos os métodos podem melhorar a nossa ánalise ao juntar palavras difernetes mas com o radical semelhante, alterando a probabilidade final e, portanto, a classificação final (material de pesquisa em \"Referências\").\n",
    "\n",
    "* Aplicar metodos de redes neurais, para podermos considerar a semantica e ordem das palavras, com o intuito de aumentar a assertividade do código.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Qualidade do Classificador a partir de novas separações das mensagens entre Treinamento e Teste\n",
    "\n",
    "Caso for fazer esse item do Projeto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Aperfeiçoamento:\n",
    "\n",
    "Trabalhos que conseguirem pelo menos conceito B vão evoluir em conceito dependendo da quantidade de itens avançados:\n",
    "\n",
    "* OK IMPLEMENTOU outras limpezas e transformações que não afetem a qualidade da informação contida nas mensagens. Ex: stemming, lemmatization, stopwords\n",
    "* OK CONSIDEROU arquivo com três categorias na classificação das variáveis (OBRIGATÓRIO PARA QUARTETOS, sem contar como item avançado)\n",
    "* CONSTRUIU o cálculo das probabilidades corretamente utilizando bigramas E apresentou referência sobre o método utilizado.\n",
    "* OK EXPLICOU porquê não pode usar o próprio classificador para gerar mais amostras de treinamento\n",
    "* OK PROPÔS diferentes cenários para Naïve Bayes fora do contexto do projeto (pelo menos dois cenários diferentes, exceto aqueles já apresentados em sala pelos professores: por exemplo, filtro de spam)\n",
    "* OK SUGERIU e EXPLICOU melhorias reais com indicações concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n",
    "* OK FEZ o item Qualidade do Classificador a partir de novas separações das mensagens entre Treinamento e Teste descrito no enunciado do projeto (OBRIGATÓRIO para conceitos A ou A+)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Referências"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**\n",
    "\n",
    "[Lemmatization vs. stemming: quando usar cada uma?](https://www.alura.com.br/artigos/lemmatization-vs-stemming-quando-usar-cada-uma) **Diferenças entre Lemmatization e stemming, e como aplicar cada uma**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# O modelo probabilistico para o calculo e classificação de texto, se baseia na probabilidade de uma palavra estar em um NPS específico. Fizemos o uso do metodo de Naive Bayes para calcular a probabilidade de uma palavra estar em um NPS específico. Com o intuito de minimizar os erros e maximizar a porcentagem de acertividade, aplicamos a suavização de Laplace dentro do código "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
